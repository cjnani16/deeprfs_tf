{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6837423564922604135\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6700198133\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8556908725863606202\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os, contextlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import datetime as dt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import scipy\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import file_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pretrained VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take pretrained model\n",
    "base_model = keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetuning model setup (might want to take those 2 fc's.. this is a lot of params)\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "base_model = vgg16.VGG16(weights='imagenet', include_top=True, pooling = None, classes=1000, input_shape=(224,224,3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.layers[-2].output\n",
    "#flattened = Flatten(name='flatten')(x)\n",
    "#fc1 = Dense(4096, name='fc1', activation='softmax', kernel_regularizer=keras.regularizers.l2(0.01))(flattened) \n",
    "#fc2 = Dense(4096, name='fc2', activation='softmax', kernel_regularizer=keras.regularizers.l2(0.01))(fc1) \n",
    "predictions = Dense(2, name='predictions', activation='softmax', kernel_regularizer=keras.regularizers.l2(0.01))(x) \n",
    "model2 = Model(inputs=base_model.input, outputs=predictions)\n",
    "mpool = Model(inputs=base_model.input, outputs=base_model.layers[-1].output)\n",
    "\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick ImageNet Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image_utils.load_img(\"./data/kitty.jpg\",target_size=(224, 224))\n",
    "plt.imshow(image)\n",
    "plt.title('kitty!')\n",
    "x = image_utils.img_to_array(image)\n",
    "x = np.expand_dims(x,0)\n",
    "x = vgg16.preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = base_model.predict(x)\n",
    "decoded_preds = vgg16.decode_predictions(preds)\n",
    "print('Predicted:', decoded_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB-WIKI Dataset - Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab images from database\n",
    "image = image_utils.load_img(file_locations.PATH_TO_IMDB_GENDER+'0/2452600_1967-08-22_2013.jpg', target_size=(224,224))\n",
    "plt.imshow(image)\n",
    "plt.title(\"human.\")\n",
    "x = image_utils.img_to_array(image)\n",
    "x = np.expand_dims(x,0)\n",
    "x = vgg16.preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=False, \n",
    "    samplewise_center=False, \n",
    "    featurewise_std_normalization=False, \n",
    "    samplewise_std_normalization=False, \n",
    "    zca_whitening=False, \n",
    "    zca_epsilon=1e-06, \n",
    "    rotation_range=0, \n",
    "    width_shift_range=0.0, \n",
    "    height_shift_range=0.0, \n",
    "    brightness_range=None, \n",
    "    shear_range=0.0, \n",
    "    zoom_range=0.0, \n",
    "    channel_shift_range=0.0, \n",
    "    fill_mode='nearest', \n",
    "    cval=0.0, \n",
    "    horizontal_flip=False, \n",
    "    vertical_flip=False, \n",
    "    rescale=None, \n",
    "    preprocessing_function=vgg16.preprocess_input, \n",
    "    data_format=None, \n",
    "    validation_split=0.2, \n",
    "    dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 32\n",
    "\n",
    "train_it = datagen.flow_from_directory(file_locations.PATH_TO_IMDB_GENDER, class_mode = 'categorical', batch_size=BS, target_size=(224,224), shuffle=True, subset='training', seed=1337)\n",
    "val_it = datagen.flow_from_directory(file_locations.PATH_TO_IMDB_GENDER, class_mode='categorical', batch_size=BS, target_size=(224,224), shuffle=False, subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks to use during trinaing\n",
    "cpcb = keras.callbacks.ModelCheckpoint(\n",
    "    './checkpoints_vgg16_tf1/weights.{}.hdf5'.format(dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")+\"-catxeloss-catacc-lr01-m09_sgd-LPHASE\"), \n",
    "    monitor='val_categorical_accuracy', verbose=1, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False, \n",
    "    mode='auto')\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choice of optimizer\n",
    "mx_opt = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0005, nesterov=True)\n",
    "model2.compile(optimizer = mx_opt, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    optimizer = \"adam\", \n",
    "    loss = 'categorical_crossentropy', \n",
    "    metrics = ['categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.25*train_it.samples // BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training (note:only using a quarter of samples for now)\n",
    "history = model2.fit_generator(\n",
    "    train_it,\n",
    "    steps_per_epoch = 0.25*train_it.samples // BS,\n",
    "    validation_data = val_it, \n",
    "    validation_steps = 0.25*train_it.samples // BS,\n",
    "    epochs = 1,\n",
    "    callbacks = [ cpcb ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend([\"train\",\"val\"])\n",
    "plt.show()\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.legend([\"train\",\"val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
